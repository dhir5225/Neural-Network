# Neural-Network

A neural network  also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature.

![image](https://user-images.githubusercontent.com/109084435/198884676-fe36a844-d134-4081-b90d-de9fc3c98b66.png)

 the algebraic formula would look something like this:
 
 ![image](https://user-images.githubusercontent.com/109084435/198884980-be7bb31d-ce8d-4fe5-baa2-72b8f2ba6071.png)

A neural network contains layers of interconnected nodes. Each node is a known as perceptron and is similar to a multiple linear regression. The perceptron feeds the signal produced by a multiple linear regression into an activation function that may be nonlinear.

### Types of neural networks

Neural networks can be classified into different types, which are used for different purposes. While this isn’t a comprehensive list of types, the below would be representative of the most common types of neural networks that you’ll come across for its common use cases:

The perceptron is the oldest neural network, created by Frank Rosenblatt in 1958. It has a single neuron and is the simplest form of a neural network:

![image](https://user-images.githubusercontent.com/109084435/198884818-afd3b6e1-0f02-464e-9998-1bda51138c18.png)

Feedforward neural networks, or multi-layer perceptrons (MLPs), are what we’ve primarily been focusing on within this article. They are comprised of an input layer, a hidden layer or layers, and an output layer. While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonlinear. Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.

Convolutional neural networks (CNNs) are similar to feedforward networks, but they’re usually utilized for image recognition, pattern recognition, and/or computer vision. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.
How do artificial intelligence, machine learning, neural networks, and deep learning relate?

Perhaps the easiest way to think about artificial intelligence, machine learning, neural networks, and deep learning is to think of them like Russian nesting dolls. Each is essentially a component of the prior term.

![image](https://user-images.githubusercontent.com/109084435/198884883-d4e4ec8d-2a21-4ec3-862f-d0bd4f8b1843.png)








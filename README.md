# Neural-Network

A neural network  also known as artificial neural networks (ANNs) or simulated neural networks (SNNs), is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates. In this sense, neural networks refer to systems of neurons, either organic or artificial in nature.

![image](https://user-images.githubusercontent.com/109084435/198884676-fe36a844-d134-4081-b90d-de9fc3c98b66.png)

 the algebraic formula would look something like this:
 
 ![image](https://user-images.githubusercontent.com/109084435/198884980-be7bb31d-ce8d-4fe5-baa2-72b8f2ba6071.png)

A neural network contains layers of interconnected nodes. Each node is a known as perceptron and is similar to a multiple linear regression. The perceptron feeds the signal produced by a multiple linear regression into an activation function that may be nonlinear.

### Types of neural networks

Neural networks can be classified into different types, which are used for different purposes. While this isn’t a comprehensive list of types, the below would be representative of the most common types of neural networks that you’ll come across for its common use cases:

The perceptron is the oldest neural network, created by Frank Rosenblatt in 1958. It has a single neuron and is the simplest form of a neural network:

![image](https://user-images.githubusercontent.com/109084435/198884818-afd3b6e1-0f02-464e-9998-1bda51138c18.png)

Feedforward neural networks, or multi-layer perceptrons (MLPs), are what we’ve primarily been focusing on within this article. They are comprised of an input layer, a hidden layer or layers, and an output layer. While these neural networks are also commonly referred to as MLPs, it’s important to note that they are actually comprised of sigmoid neurons, not perceptrons, as most real-world problems are nonlinear. Data usually is fed into these models to train them, and they are the foundation for computer vision, natural language processing, and other neural networks.

Recurrent Neural Networks-A more complex type of neural network, recurrent neural networks take the output of a processing node and transmit the information back into the network. This results in theoretical "learning" and improvement of the network. Each node stores historical processes, and these historical processes are reused in the future during processing.

Convolutional neural networks (CNNs) are similar to feedforward networks, but they’re usually utilized for image recognition, pattern recognition, and/or computer vision. These networks harness principles from linear algebra, particularly matrix multiplication, to identify patterns within an image.
How do artificial intelligence, machine learning, neural networks, and deep learning relate?

Deconvolutional neural networks simply work in reverse of convolutional neural networks. The application of the network is to detect items that might have been recognized as important under a convolutional neural network. These items would likely have been discarded during the convolutional neural network execution process. This type of neural network is also widely used for image analysis or processing.

Perhaps the easiest way to think about artificial intelligence, machine learning, neural networks, and deep learning is to think of them like Russian nesting dolls. Each is essentially a component of the prior term.

![image](https://user-images.githubusercontent.com/109084435/198884883-d4e4ec8d-2a21-4ec3-862f-d0bd4f8b1843.png)

### Application of Neural Networks

Neural networks are broadly used, with applications for financial operations, enterprise planning, trading, business analytics, and product maintenance. Neural networks have also gained widespread adoption in business applications such as forecasting and marketing research solutions, fraud detection, and risk assessment.

A neural network evaluates price data and unearths opportunities for making trade decisions based on the data analysis. The networks can distinguish subtle nonlinear interdependencies and patterns other methods of technical analysis cannot. According to research, the accuracy of neural networks in making price predictions for stocks differs. Some models predict the correct stock prices 50 to 60% of the time, while others are accurate in 70% of all instances. Some have posited that a 10% improvement in efficiency is all an investor can ask for from a neural network.

Specific to finance, neural networks can process hundreds of thousands of bits of transaction data. This can translate to a better understanding of trading volume, trading range, correlation between assets, or setting volatility expectations for certain investments. As a human may not be able to efficiently pour through years of data (sometimes collected down second intervals), neural networks can be designed to spot trends, analyze outcomes, and predict future asset class value movements.

### Advantages and Disadvantages of Neural Networks

#### Advantages of Neural Networks

Neutral networks that can work continuously and are more efficient than humans or simpler analytical models. Neural networks can also be programmed to learn from prior outputs to determine future outcomes based on the similarity to prior inputs.

Neural networks that leverage cloud of online services also have the benefit of risk mitigation compared to systems that rely on local technology hardware. In addition, neural networks can often perform multiple tasks simultaneously (or at least distribute tasks to be performed by modular networks at the same time).

Last, neural networks are continually being expanded into new applications. While early, theoretical neural networks were very limited to its applicability into different fields, neural networks today are leveraged in medicine, science, finance, agriculture, or security.

#### Disadvantages of Neural Networks

Though neutral networks may rely on online platforms, there is still a hardware component that is required to create the neural network. This creates a physical risk of the network that relies on complex systems, set-up requirements, and potential physical maintenance.

Though the complexity of neural networks is a strength, this may mean it takes months (if not longer) to develop a specific algorithm for a specific task. In addition, it may be difficult to spot any errors or deficiencies in the process, especially if the results are estimates or theoretical ranges.

Neural networks may also be difficult to audit. Some neural network processes may feel "like a black box" where input is entered, networks perform complicated processes, and output is reported. It may also be difficult for individuals to analyze weaknesses within the calculation or learning process of the network if the network lacks general transparency on how a model learns upon prior activity.

### The Neural Network Model & How do neural networks work?

Input data (Yellow) are processed against a hidden layer (Blue) and modified against another hidden layer (Green) to produce the final output (Red).

![image](https://user-images.githubusercontent.com/109084435/205476546-0046278d-7aac-48db-a2e2-c1b6299b1094.png)

The human brain is the inspiration behind neural network architecture. Human brain cells, called neurons, form a complex, highly interconnected network and send electrical signals to each other to help humans process information. Similarly, an artificial neural network is made of artificial neurons that work together to solve a problem. Artificial neurons are software modules, called nodes, and artificial neural networks are software programs or algorithms that, at their core, use computing systems to solve mathematical calculations.

Simple neural network architecture

A basic neural network has interconnected artificial neurons in three layers:

##### Input Layer

Information from the outside world enters the artificial neural network from the input layer. Input nodes process the data, analyze or categorize it, and pass it on to the next layer.

##### Hidden Layer

Hidden layers take their input from the input layer or other hidden layers. Artificial neural networks can have a large number of hidden layers. Each hidden layer analyzes the output from the previous layer, processes it further, and passes it on to the next layer.

###### Output Layer

The output layer gives the final result of all the data processing by the artificial neural network. It can have single or multiple nodes. For instance, if we have a binary (yes/no) classification problem, the output layer will have one output node, which will give the result as 1 or 0. However, if we have a multi-class classification problem, the output layer might consist of more than one output node.

#### Applications of artificial neural networks

-Image recognition was one of the first areas to which neural networks were successfully applied, but the technology uses have expanded to many more areas, including:

-Chatbots

-Natural language processing, translation and language generation

-Stock market prediction

-Delivery driver route planning and optimization

-Drug discovery and development

These are just a few specific areas to which neural networks are being applied today. Prime uses involve any process that operates according to strict rules or patterns and has large amounts of data. If the data involved is too large for a human to make sense of in a reasonable amount of time, the process is likely a prime candidate for automation through artificial neural network







